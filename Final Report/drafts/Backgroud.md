# Background

## The Lanchester Dynamics

The Lanchester dynamics were theorises by Fredrick Lanchester in 1916 in order to model attrition rates during a battle in his paper “Aircraft in Warfare, the dawn of the fourth arm”. \cite{lanchester1995aircraft} Two independent systems were proposed: Aimed and unaimed models. With unaimed fire, like mortar and artillery bombardment, the rate of loss is proportional to the product of the size of both forces. In my project I will be focused on aimed fire where unaimed fire could be used in support. When a battle consists of aimed fire, the rate of loss of as side is proportional to size of opposing force. 

 This model contains conserved quantities,
    
, which allows you to determine the outcome of the engagement from the initial conditions and the attrition factors. The sign of the constant will determine the victor of the battle and using the magnitude and you can find the size of that remaining force. 

 The model has been adapted and applied to the complexity of asymmetric battles such as in guerrilla warfare, multi-side battles commonly found in civil wars and combined arm combat, the way modern national armies are likely to fight.

It was suggested that to model heterogeneous combat using these dynamics the constants are calculated as “The square of the sum of the square roots of the strengths of its individual units” and size of the force is the sum of each arm. \cite{lanchester1995aircraft}. It has been showed that this assumption that Lanchester made about heterogenous combat is oversimplified and generally do not hold. \cite{Lin2014}

The modelling of past battles has been used in order to test the legitimacy of the Lanchester model. The application of Lanchester system to the Ardennes campaign has been studied because of the availability of data for this battle. It was initially found that the campaign fit Lanchester’s linear law, however after being reviewed the resulting model was roughly an exponent of 1.5.  Some shortcomings of the paper are the oversimplifications of combined arms combat using the outdated oversimplification of heterogenous combat, in addition, with force sizes being so large (1.7 million men in total) and the true battle was the cumulative efforts of several smaller battles. 
A study into the Battle of Iwo Jima have shown that from the data of troop numbers a Lanchester System can be exist that following the square law. \cite{Willard1962} However, the methodology of Engel has been disputed since he used the same data set to estimate constants as he did test. \cite{Willard1962} The US Civil War was studied, and it was concluded that on smaller scales the square law fits well when troop sizes are below 15,000 on each side, while with forces larger than that the proportions of those injured increases. In general, most research in comparing real data to the Lanchester Dynamics conclude that on small, individual battle scales, the dynamics can accurately model combat however in larger scales the model falls apart. \cite{Weiss} This may be from the complexity added from advanced tactics and the oversimplification of multiple smaller battles being modelled as a single campaign.

Alterations have been made to the Lanchester dynamics in order to model asymmetric engagements. M. B. Schaffer has developed systems to model guerrilla combat that took place in Vietnam. These models are significantly more complex than Lanchester’s original system, taking into consideration more complex factors such as desertion and recruitment rates of the guerrilla force and the effects of morale as a battle takes place.\cite{Schaffer1967} In addition to the addition of extra attrition factors the inclusion of the effects of supporting arms such as artillery results in an incredibly complex model with more involved methods in predicting the outcome. 

Modelling modern counter-insurgency operations have some changes compared to their Vietnam era counterparts, for instance these models include the effects of intelligence, the ability to determine the enemy from the civilian population. In addition, the effects of accidental civilian casualties and their role in recruitment is explored as a factor in the model. The inclusion of such factors increases the complexity of the analytic solutions when trying to limit recruitment and having an exponential cost on increasing intelligence.

Multiple factions are common occurrences during civil wars. Modelling these conflicts with an adapted Lanchester system has been used in order to model this. In these situations, the most important point is the time at least one force is destroying. \cite{Kress2018}
 After this it transitions into a regular Lanchester system. There is also the chance that multiple forces are destroyed at the same time resulting in a victor without a transition into a regular Lanchester system. This model technique for multifaction combat has potential to be easily scales to many more factions. However, in this field there has not been progress in the optimisation of engagement strategy to increase survivability. 

The effects of reserve troops and reallocation of forces (aggregating and disaggregation) has been studied by P.K. Davis. \cite{Davis1995} This is achieved by modelling having reserve units joining the battle and then having troops on the edges and flanks of the conflict transitioning their focus onto the centre of the battle. The most important factor for a successful battle is the ratios between the time to redeploy troops, the time of the whole battle and the time to deploy reserve troops. For example, if a large proportion of the battle has taken place before the reserve troops are ready to fight, then the likelihood of winning the engagement would be much smaller than compared to if the reserve troops had arrived earlier.

R. K. Colegrove and J. M. Hyde have created a simple heterogenous combat model that follows the original Lanchester dynamics. This model treats every arm of each side as its own force with its own attrition rates, based on the size of the enemy forces. This modelling technique uses Hamiltonian systems, which allows the prediction of the outcome of a battle from initial conditions, like in the original dynamics. This papers scope is limited to the attrition factors being constant along the whole engagement, which generally results in a non-optimal solution for each force.\cite{Colegrave1993}

Optimisation techniques for a single side against a heterogenous enemy has been researched since these are the simplest engagements where a strategy or choice can be made to change the outcome of the battle. Y. Friedman attempted to provide a solution to the optimisation by proving the solution of the homogenous force attacking the arm which will be the most damaged by their attack or the most dangerous arm, one that can do the most damage to the homogenous force. K.Y. Lin and N.J. MacKay combined these two rules to create a general solution which they then proved is optimal in all situations. They suggest that the homogeneous side should wholly focusing fire onto the enemy arm where the product of the attrition factor of the enemy arm attacking the homogeneous side and the attrition factor of the homogenous force against that enemy are is the largest. The proof that this is the mathematically optimal solution to one-to-many engagements was provided and so far, there has not been many challenges to their work.

## Optimisation Techniques

<!-- With the additional complexity found in the heterogenous combat models, finding an analytical solution to our optimisation problem will be very difficult. Therefore, we must use optimisation techniques to find our solution. In order to successfully optimise the problem, we must understand the different techniques that are in use. From the understanding the different techniques, we will be able to discount some methods that are unlikely to work and focus our efforts on techniques with a higher chance of success.
The techniques I will focus on are those which are able to avoid getting trapped in local minima.

I intend to test the use of simulated annealing on the model. This is an iterative method which involves picking random points and checking if they are better solutions to the current optimal solution then reducing the spread of the randomness function. This is repeated until the randomness is 0 and a solution is found. This is a useful technique for functions where there may be many local minima since immediate proximity to the optimal solution is not a factor until later in the process.\cite{Connolly1992}

In addition to simulated annealing I will attempt to use tabu search which unlike other local searches will move to a weaker position if there are no adjacent points with a more optimal solution. This results in tabu search being able to get out of local maxima to more optimal positions. \cite{Gendreau2003}

The final method I will use is stochastic hill climbing because I suspect with the complexity of the model there will be several local maxima so the use of stochastic hill climbing over regular hill climbing would mitigate the risk of getting stuck in local maxima.\cite{shillclimbing}

By conducting my literature review, I see there is a clear gap in knowledge in this space. The closest two papers to my problem are those about extending the Lanchester Model to (2,2) conflicts by R. K. Colegrove and J. M. Hyde and optimal policy in one against many engagements by K.Y. Lin and N.J. MacKay. With the first paper providing a good framework for my simulation and the second paper providing an analytical solution for a simpler optimisation problem that is very close to my problem. Although these are not directly like my problem, using their research I can verify my simulations are running correctly. My research into the optimisation techniques allows will allow me to correctly implement these and test their effectiveness in the problem. -->
