%% ----------------------------------------------------------------
%% Previous Work.tex
%% ---------------------------------------------------------------- 
\chapter{Design} \label{Chapter:three}

\section{Simulation}

The simulation function takes in a scenario, which is the initial conditions of the *battle* and an allocation matrix and will return a score, which is the *formula* or the sum of the friend force minus the sum of enemy forces. This function will be used to score allocation matrices. Originally this score was just the sum of the friendly force but the size of enemy force was included in order to allow the functions to score *unwinnable* scenarios where the aim of the allocation is to reduce the losses incurred. The function achieves this by using a while loop that will continue to loop until one of the sides is completely destroyed, or the sum of their force is 0.

\section{Optimisation Algorithms}

For each of these optimisation algorithms I will explain how I intend to implement them, with the help of pseudo code.

\subsection{Hill Climbing}

This should start with a randomly generated allocation matrix. Then the algorithm will enter a for loop. For each iteration a new allocation matrix will be randomly generated. This matrix will then be multiplied by a random small number, this scaled matrix is then added or subtracted to the original allocation matrix. Then the allocation matrix is scored and if this score is greater than the currently selected allocation matrix, will replace the selected allocation matrix. Eventually the allocation matrix will improve however when the program has been running longer the number of iterations required to find a better allocation matrix will increase.

\subsection{Gradient Descent}

Since the allocation matrix is not differentiable with respect to the score, an approximation of the gradient will be calculated by adding a small delta (e.g. 0.0001) and rerunning the simulation. The difference between this new score and original score will be stored in a differential matrix with the same i and j indices of the element that was changed.
*INCLUDE PSEUDO CODE TO EXPLAIN*
By doing this for each element of the allocation matrix, the differential is approximated. With this approximation of the differential. This differential will then be multipled by the learning rate then added to the allocation matrix, which will then be normalised to fit the constraints. By adding the gradient of the allocation matrix the score should improve since this is the steepest direction, so the direction where the score will increase the most.

\subsection{Simulated Annealing}

Simulated annealing should be implemented in a similar way to hill climbing. The only difference is when the new score is worse than the previous attempt. When a worse allocation matrix is found the a probability threshold is generated based on how worse the new score is and the iteration te score is found. *Insert FORMULA*. A random number will be generated between 0 and 1 and if this number is less than the probability threshold the new lower score will be used in the next iteration.

\subsection{Genetic Algorithms}

The genetic algorithm will start with a population of randomly generated allocation matrices. This initial population will then be scored and sorted from the best scoring to worst scoring from the population. A proportion of the top scoring allocations will be used as a breeding population. From this breeding population 2 parents will be randomly chosen. Crossover takes place by randomly copying columns of the parents' allocation matrix. This also means there would be no need to normalise the matrix as the constraints will not be voided. In order to mutate a random number will be generated between 0 and 1 and if this number is less than the mutation rate a mutation will occur. This mutation will be similar to the *steps* taken in the hill climbing and simulated annealing. This new population is then scored and this repeats for a number of iterations.

\subsection{Particle Swarm Optimisation}

Like a genetic algorithm this algorithm requires a large population to work effectively. A population is made up of *particles*. For each *particle* the population 2 randomly generated allocation matrices are created. The first one is used as the first allocation matrix for that particle and the second allocation matrix is the particles initial velocity. The *particles* in the initial population are then scored and these scores and allocations are stored as the best position found for each particle. In addition the overall best scoring matrix is saved as the overall best score. After this the next step is calculated by adding the previous step, the difference between the particles allocation that achieved the best score and the current allocation and the difference between the overall best scoring allocation and the particles allocation.
